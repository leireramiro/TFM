{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4f8ed3-90f0-4203-bdf8-5da220dc2463",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Augmentation with Noise Injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a6a44-0bbd-43eb-be9f-219919fae886",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c3971d-54e1-4b40-bff5-3cb0737f3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "import pickle # for loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec4d14-f9f6-456f-8a8e-bb0dbcc40e9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44113afc-ae9d-47d7-bc60-cba5718d1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = open('df.pickle', 'rb')\n",
    "df = pickle.load(f_df)\n",
    "f_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8befaa-82ee-43d5-b693-28a54f6f9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_test = open('train_test.pickle', 'rb')\n",
    "(train,test) = pickle.load(f_train_test)\n",
    "f_train_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16e7ef6-d809-4789-8bcc-61f604b21d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_samples = open('train_samples.pickle', 'rb')\n",
    "(train10, train20, train30, train40, train50, train60, train70, train80, train90) = pickle.load(f_train_samples)\n",
    "f_train_samples.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff315863-3759-4fc3-afb5-43e24680a4cf",
   "metadata": {},
   "source": [
    "## Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc45f521-3a34-4131-aed9-593ad6184733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopNWords(df,scl,n=10):\n",
    "    \n",
    "    l_topN_words = []\n",
    "    \n",
    "    tfidf = TfidfVectorizer(min_df=3,\n",
    "                                max_features=5000,\n",
    "                                stop_words='english')\n",
    "    \n",
    "    corpus = df[['lyrics']].values.flatten()\n",
    "    \n",
    "    corpus_tfidf=tfidf.fit_transform(corpus)\n",
    "    \n",
    "    feature_names = np.array(tfidf.get_feature_names())\n",
    "    \n",
    "    ch2 = SelectKBest(chi2, k=1000)\n",
    "    ch2.fit(corpus_tfidf, df[[scl]].values)\n",
    "    \n",
    "    for st in tqdm([\"H\",\"MH\",\"ML\",\"L\"]):\n",
    "        \n",
    "        df_n=df[df[scl] == st].reset_index(drop=True)\n",
    "        \n",
    "        corpus_n = df_n[['lyrics']].values.flatten()\n",
    "        \n",
    "        corpus_n_tfidf = tfidf.transform(corpus_n).toarray()\n",
    "        \n",
    "        corpus_n_chi = ch2.transform(corpus_n_tfidf)\n",
    "        \n",
    "        importance = np.argsort(np.asarray(corpus_n_chi.sum(axis=0)).ravel())[::-1]\n",
    "        \n",
    "        topN_words = list(feature_names[importance[:n]])\n",
    "    \n",
    "        l_topN_words.append(topN_words)\n",
    "        \n",
    "    return(l_topN_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eae382e-41f2-47ca-92a9-86a905faa2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NOISE_augment_df(df,sc,scl,w_l,n=5,samples=100):\n",
    "    \n",
    "    random.seed(79068588)\n",
    "    \n",
    "    ind = 1\n",
    "    \n",
    "    for st in [\"H\",\"MH\",\"ML\",\"L\"]:\n",
    "        \n",
    "        df_n=df[df[scl] == st].reset_index(drop=True)\n",
    "        \n",
    "        new_text=[]\n",
    "        sc_list=[]\n",
    "        \n",
    "        n_samples = int(samples//4)\n",
    "        \n",
    "        if ind==4:\n",
    "            n_samples = samples-3*n_samples\n",
    "        \n",
    "            \n",
    "        ## data augmentation loop\n",
    "        random.seed(79068588)\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),n_samples)):\n",
    "            random.seed(79068588)\n",
    "            text = df_n.iloc[i]['lyrics'].split()\n",
    "            \n",
    "            random.seed(79068588)\n",
    "            words_l = w_l[ind-1]\n",
    "            #.tolist()\n",
    "            words_l = random.sample(words_l,n)\n",
    "            \n",
    "            augmented_text_l = text+words_l\n",
    "            random.shuffle(augmented_text_l)\n",
    "            \n",
    "            augmented_text = ' '.join(map(str, augmented_text_l))\n",
    "            \n",
    "            new_text.append(augmented_text)\n",
    "                \n",
    "            sc_list.append(df_n.iloc[i][sc])\n",
    "    \n",
    "        ind =+ 1\n",
    "    \n",
    "        ## dataframe\n",
    "        new=pd.DataFrame({'lyrics':new_text, sc+' level':st, sc:sc_list})\n",
    "        df=df.append(new,ignore_index = True)\n",
    "        \n",
    "    return df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c132e-2c90-4c0a-b959-303d84fb4c6c",
   "metadata": {},
   "source": [
    "### Noise injection (n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4217ccb1-6a94-401d-8b92-bde16ec005cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "energy_top_words = TopNWords(train, scl='energy level', n=20)\n",
    "\n",
    "valence_top_words = TopNWords(train, scl='valence level', n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610855de-adb3-45e2-9e7e-2710c359ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5101/5101 [00:01<00:00, 2664.39it/s]\n",
      "100%|██████████| 5101/5101 [00:02<00:00, 2276.89it/s]\n",
      "100%|██████████| 5101/5101 [00:01<00:00, 2559.57it/s]\n",
      "100%|██████████| 5101/5101 [00:01<00:00, 2553.46it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2441.92it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2655.82it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2610.03it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2733.06it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2599.91it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2302.76it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2688.99it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2734.85it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2329.24it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2521.15it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2610.57it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2759.54it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2470.73it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2537.11it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2743.53it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2685.10it/s]\n",
      "100%|██████████| 2267/2267 [00:01<00:00, 2243.71it/s]\n",
      "100%|██████████| 2267/2267 [00:01<00:00, 2162.20it/s]\n",
      "100%|██████████| 2267/2267 [00:00<00:00, 2555.04it/s]\n",
      "100%|██████████| 2267/2267 [00:00<00:00, 2452.69it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 2204.08it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 1874.34it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 2380.40it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 2349.18it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2596.81it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2532.54it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2033.51it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2983.65it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2291.70it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2790.49it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2937.83it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 3058.63it/s]\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train)\n",
    "\n",
    "train10_energy_aug2 = NOISE_augment_df(train10[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train10)))\n",
    "train20_energy_aug2 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train20)))\n",
    "train30_energy_aug2 = NOISE_augment_df(train30[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train30)))\n",
    "train40_energy_aug2 = NOISE_augment_df(train40[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train40)))\n",
    "train50_energy_aug2 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train50)))\n",
    "train60_energy_aug2 = NOISE_augment_df(train60[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train60)))\n",
    "train70_energy_aug2 = NOISE_augment_df(train70[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train70)))\n",
    "train80_energy_aug2 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train80)))\n",
    "train90_energy_aug2 = NOISE_augment_df(train90[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, samples=(n_train-len(train90)))\n",
    "\n",
    "train_energy_aug2 = train[['lyrics','energy','energy level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d89141-b294-4e21-8104-069fdc8b839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train augmented samples dfs, n=5\n",
    "f_train_energy_samples_aug2 = open('train_energy_samples_aug2.pickle', 'wb')\n",
    "pickle.dump([train10_energy_aug2,train20_energy_aug2,train30_energy_aug2,train40_energy_aug2,train50_energy_aug2,train60_energy_aug2,train70_energy_aug2,train80_energy_aug2,train90_energy_aug2,train_energy_aug2], f_train_energy_samples_aug2)\n",
    "f_train_energy_samples_aug2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6388c86-095e-4e5d-a15d-32aa08fad041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5101/5101 [00:01<00:00, 2685.10it/s]\n",
      "100%|██████████| 5101/5101 [00:01<00:00, 2796.24it/s]\n",
      "100%|██████████| 5101/5101 [00:02<00:00, 2255.32it/s]\n",
      "100%|██████████| 5101/5101 [00:01<00:00, 2565.91it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 1935.64it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 2045.73it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2358.53it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 1921.22it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2618.43it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2316.87it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2584.24it/s]\n",
      "100%|██████████| 3968/3968 [00:01<00:00, 2836.47it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2813.11it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2717.21it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2553.61it/s]\n",
      "100%|██████████| 3401/3401 [00:01<00:00, 2324.32it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2053.47it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2345.87it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2256.03it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2171.73it/s]\n",
      "100%|██████████| 2267/2267 [00:00<00:00, 2300.06it/s]\n",
      "100%|██████████| 2267/2267 [00:01<00:00, 2194.13it/s]\n",
      "100%|██████████| 2267/2267 [00:00<00:00, 2329.73it/s]\n",
      "100%|██████████| 2267/2267 [00:00<00:00, 2644.38it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 1865.82it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 1837.47it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 1954.50it/s]\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 2528.13it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2396.50it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2633.59it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2471.03it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2584.66it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2447.84it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2578.48it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2403.77it/s]\n",
      "100%|██████████| 567/567 [00:00<00:00, 2510.88it/s]\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train)\n",
    "\n",
    "train10_valence_aug2 = NOISE_augment_df(train10[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train10)))\n",
    "train20_valence_aug2 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train20)))\n",
    "train30_valence_aug2 = NOISE_augment_df(train30[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train30)))\n",
    "train40_valence_aug2 = NOISE_augment_df(train40[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train40)))\n",
    "train50_valence_aug2 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train50)))\n",
    "train60_valence_aug2 = NOISE_augment_df(train60[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train60)))\n",
    "train70_valence_aug2 = NOISE_augment_df(train70[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train70)))\n",
    "train80_valence_aug2 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train80)))\n",
    "train90_valence_aug2 = NOISE_augment_df(train90[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, samples=(n_train-len(train90)))\n",
    "\n",
    "train_valence_aug2 = train[['lyrics','valence','valence level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d912d47f-a968-4a60-9073-271c91418f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train augmented samples dfs, n=5\n",
    "f_train_valence_samples_aug2 = open('train_valence_samples_aug2.pickle', 'wb')\n",
    "pickle.dump([train10_valence_aug2,train20_valence_aug2,train30_valence_aug2,train40_valence_aug2,train50_valence_aug2,train60_valence_aug2,train70_valence_aug2,train80_valence_aug2,train90_valence_aug2,train_valence_aug2], f_train_valence_samples_aug2)\n",
    "f_train_valence_samples_aug2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031219c-7abf-43e8-ae96-a4e6e105bda0",
   "metadata": {},
   "source": [
    "### Noise injection for different n values (with 20%, 50% and 80% of training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd0997-f42c-4e4e-8911-8a9c432a893e",
   "metadata": {},
   "source": [
    "#### Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a811c5-549f-4412-83ad-791d1258e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.27it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "energy_top_words = TopNWords(train, scl='energy level', n=50)\n",
    "\n",
    "valence_top_words = TopNWords(train, scl='valence level', n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c58b522b-b0e4-43e8-be3f-756764ed3d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4534/4534 [00:01<00:00, 2638.66it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2520.09it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2828.37it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2915.58it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2352.36it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2600.49it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2615.00it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2974.75it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2750.56it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 2103.43it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 1707.49it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2355.17it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2343.27it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2554.80it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2615.69it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2532.39it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2504.04it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2499.34it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2575.79it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2641.86it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2744.37it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2720.51it/s]\n",
      "100%|██████████| 2834/2834 [00:00<00:00, 2868.78it/s]\n",
      "100%|██████████| 2834/2834 [00:00<00:00, 2940.07it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2555.60it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2545.35it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2742.69it/s]\n",
      "100%|██████████| 2834/2834 [00:00<00:00, 2861.69it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2606.42it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2585.42it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2302.16it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2743.94it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2540.67it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2557.97it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2620.47it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2694.13it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2485.06it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2495.95it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2577.40it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2603.55it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2751.17it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2606.13it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2121.60it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2904.76it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2670.08it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2564.66it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2728.10it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2847.76it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2527.40it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2565.25it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2279.72it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 1442.31it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2439.55it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2476.90it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2601.11it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2688.82it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2488.43it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2439.19it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2477.70it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2573.78it/s]\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train)\n",
    "\n",
    "\n",
    "train20_energy_aug_n1 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=1, samples=(n_train-len(train20)))\n",
    "train20_energy_aug_n2 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=5, samples=(n_train-len(train20)))\n",
    "train20_energy_aug_n3 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=10, samples=(n_train-len(train20)))\n",
    "train20_energy_aug_n4 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=15, samples=(n_train-len(train20)))\n",
    "train20_energy_aug_n5 = NOISE_augment_df(train20[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=20, samples=(n_train-len(train20)))\n",
    "\n",
    "\n",
    "train50_energy_aug_n1 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=1, samples=(n_train-len(train50)))\n",
    "train50_energy_aug_n2 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=5, samples=(n_train-len(train50)))\n",
    "train50_energy_aug_n3 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=10, samples=(n_train-len(train50)))\n",
    "train50_energy_aug_n4 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=15, samples=(n_train-len(train50)))\n",
    "train50_energy_aug_n5 = NOISE_augment_df(train50[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=20, samples=(n_train-len(train50)))\n",
    "\n",
    "\n",
    "train80_energy_aug_n1 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=1, samples=(n_train-len(train80)))\n",
    "train80_energy_aug_n2 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=5, samples=(n_train-len(train80)))\n",
    "train80_energy_aug_n3 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=10, samples=(n_train-len(train80)))\n",
    "train80_energy_aug_n4 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=15, samples=(n_train-len(train80)))\n",
    "train80_energy_aug_n5 = NOISE_augment_df(train80[['lyrics','energy','energy level']], sc='energy', scl='energy level', w_l=energy_top_words, n=20, samples=(n_train-len(train80)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e56fe90-bc2a-4de6-b9fb-fe57ae8a8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train augmented samples dfs, different n values\n",
    "f_train_energy_samples_aug_n = open('train_energy_samples_aug_n.pickle', 'wb')\n",
    "pickle.dump([train20_energy_aug_n1,train20_energy_aug_n2,train20_energy_aug_n3,train20_energy_aug_n4,train20_energy_aug_n5,train50_energy_aug_n1,train50_energy_aug_n2,train50_energy_aug_n3,train50_energy_aug_n4,train50_energy_aug_n5,train80_energy_aug_n1,train80_energy_aug_n2,train80_energy_aug_n3,train80_energy_aug_n4,train80_energy_aug_n5], f_train_energy_samples_aug_n)\n",
    "f_train_energy_samples_aug_n.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756fce0-f58d-4050-bb50-effad5a8a8ea",
   "metadata": {},
   "source": [
    "#### Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8832b0ff-2fd2-46f3-bc67-17238b7060f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4534/4534 [00:01<00:00, 2846.05it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 1961.40it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2294.65it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 2168.01it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2704.59it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2739.94it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2799.80it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2840.94it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2459.09it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2634.55it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2663.69it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2716.01it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 2136.84it/s]\n",
      "100%|██████████| 4534/4534 [00:02<00:00, 1993.69it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2526.70it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2506.34it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2501.34it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2513.08it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2553.54it/s]\n",
      "100%|██████████| 4534/4534 [00:01<00:00, 2588.31it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2718.93it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2735.32it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2540.64it/s]\n",
      "100%|██████████| 2834/2834 [00:00<00:00, 2868.48it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2565.05it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2709.65it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2767.00it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2774.58it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2282.90it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2604.47it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2668.78it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2316.22it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2130.70it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2040.84it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2385.51it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2631.46it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2470.17it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2229.31it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2525.55it/s]\n",
      "100%|██████████| 2834/2834 [00:01<00:00, 2554.58it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2606.64it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2560.63it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2714.67it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2839.94it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2626.30it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2693.88it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2724.43it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2502.52it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2409.66it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 1766.97it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 1980.87it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2182.82it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2088.78it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2144.81it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2320.27it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2464.94it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2413.67it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2422.47it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2467.63it/s]\n",
      "100%|██████████| 1133/1133 [00:00<00:00, 2556.60it/s]\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train)\n",
    "\n",
    "\n",
    "train20_valence_aug_n1 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=1, samples=(n_train-len(train20)))\n",
    "train20_valence_aug_n2 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=5, samples=(n_train-len(train20)))\n",
    "train20_valence_aug_n3 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=10, samples=(n_train-len(train20)))\n",
    "train20_valence_aug_n4 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=15, samples=(n_train-len(train20)))\n",
    "train20_valence_aug_n5 = NOISE_augment_df(train20[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=20, samples=(n_train-len(train20)))\n",
    "\n",
    "\n",
    "train50_valence_aug_n1 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=1, samples=(n_train-len(train50)))\n",
    "train50_valence_aug_n2 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=5, samples=(n_train-len(train50)))\n",
    "train50_valence_aug_n3 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=10, samples=(n_train-len(train50)))\n",
    "train50_valence_aug_n4 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=15, samples=(n_train-len(train50)))\n",
    "train50_valence_aug_n5 = NOISE_augment_df(train50[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=20, samples=(n_train-len(train50)))\n",
    "\n",
    "\n",
    "train80_valence_aug_n1 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=1, samples=(n_train-len(train80)))\n",
    "train80_valence_aug_n2 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=5, samples=(n_train-len(train80)))\n",
    "train80_valence_aug_n3 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=10, samples=(n_train-len(train80)))\n",
    "train80_valence_aug_n4 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=15, samples=(n_train-len(train80)))\n",
    "train80_valence_aug_n5 = NOISE_augment_df(train80[['lyrics','valence','valence level']], sc='valence', scl='valence level', w_l=valence_top_words, n=20, samples=(n_train-len(train80)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b384c7-4b81-49a4-8e76-733875eca59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train augmented samples dfs, different n values\n",
    "f_train_valence_samples_aug_n = open('train_valence_samples_aug_n.pickle', 'wb')\n",
    "pickle.dump([train20_valence_aug_n1,train20_valence_aug_n2,train20_valence_aug_n3,train20_valence_aug_n4,train20_valence_aug_n5,train50_valence_aug_n1,train50_valence_aug_n2,train50_valence_aug_n3,train50_valence_aug_n4,train50_valence_aug_n5,train80_valence_aug_n1,train80_valence_aug_n2,train80_valence_aug_n3,train80_valence_aug_n4,train80_valence_aug_n5], f_train_valence_samples_aug_n)\n",
    "f_train_valence_samples_aug_n.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
